"""
PsyCounselor - å¿ƒç†å’¨è¯¢ RAG ç³»ç»Ÿï¼ˆä¸»åº”ç”¨ï¼‰
é›†æˆå±æœºæ£€æµ‹ã€RAGæ£€ç´¢ã€å¤§æ¨¡å‹ç”Ÿæˆ
é‡æ„ç‰ˆæœ¬ï¼šé‡‡ç”¨æ¨¡å—åŒ–è·¯ç”±è®¾è®¡ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
"""

import os
import sys
import numpy as np
import pickle
import faiss
import json
import torch
from datetime import datetime
from io import BytesIO

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼ˆç¡®ä¿èƒ½å¯¼å…¥æ‰€æœ‰æ¨¡å—ï¼‰
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥FastAPIç›¸å…³
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# å¯¼å…¥å„ä¸ªåŠŸèƒ½æ¨¡å—
from memory import get_user_memory, ConversationMemory
from transformers import AutoTokenizer, AutoModel
from lmdeploy import pipeline as lmdeploy_pipeline, TurbomindEngineConfig

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from crisis_detector import CrisisDetector, CRISIS_RESPONSE
from emotion_analyzer import EmotionTracker
from personality_profiler import PersonalityProfiler
from recommendation_engine import RecommendationEngine

# å¯¼å…¥è·¯ç”±æ¨¡å—
from chat_routes import router as chat_router
from health_routes import router as health_router
from crisis_routes import router as crisis_router
from memory_routes import router as memory_router
from emotion_routes import router as emotion_router
from personality_routes import router as personality_router
from recommendation_routes import router as recommendation_router
from report_routes import router as report_router

# ========== FastAPI åº”ç”¨å®ä¾‹ ==========
app = FastAPI(
    title="PsyCounselor API - å®‰å…¨å¢å¼ºç‰ˆ",
    description="åŸºäº Qwen3-32B + RAG çš„å¿ƒç†å’¨è¯¢ç³»ç»Ÿï¼Œé›†æˆå±æœºè¯†åˆ«ä¸å®‰å…¨å¹²é¢„",
    version="2.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶ä»¥æ”¯æŒè·¨åŸŸè¯·æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== é…ç½®è·¯å¾„ ==========
MODEL_PATH = "/root/lanyun-tmp/heart/models/bge_large_zh_v1.5"
INDEX_PATH = "/root/lanyun-tmp/heart/data/psydt_index"
LLM_PATH = "/root/lanyun-tmp/heart/models/qwen3_32b_awq"

print("=" * 60)
print("ğŸš€ æ­£åœ¨å¯åŠ¨ PsyCounselor å®‰å…¨å¢å¼ºç‰ˆ...")
print("=" * 60)

# ========== åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ ==========
print("\n[1/4] åŠ è½½å±æœºæ£€æµ‹æ¨¡å—...")
crisis_detector = CrisisDetector(use_semantic=True)
print("âœ… å±æœºæ£€æµ‹æ¨¡å—å°±ç»ªï¼ˆå…³é”®è¯+BERTåŒé‡æ£€æµ‹ï¼‰")

print("\n[1.5/4] åŠ è½½æƒ…ç»ªåˆ†ææ¨¡å—...")
emotion_tracker = EmotionTracker()
print("âœ… æƒ…ç»ªåˆ†ææ¨¡å—å°±ç»ª")

print("\n[1.7/4] åŠ è½½äººæ ¼ç”»åƒåˆ†ææ¨¡å—...")
personality_profiler = PersonalityProfiler()
print("âœ… äººæ ¼ç”»åƒåˆ†ææ¨¡å—å°±ç»ª")

print("\n[1.8/4] åŠ è½½ä¸ªæ€§åŒ–å»ºè®®å¼•æ“...")
recommendation_engine = RecommendationEngine()
print("âœ… ä¸ªæ€§åŒ–å»ºè®®å¼•æ“å°±ç»ª")

print("\n[2/4] åŠ è½½ BGE åµŒå…¥æ¨¡å‹ï¼ˆCPUï¼‰...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
embed_model = AutoModel.from_pretrained(MODEL_PATH, trust_remote_code=True).to("cpu")
embed_model.eval()
print("âœ… BGE æ¨¡å‹å°±ç»ª")

print("\n[3/4] åŠ è½½ FAISS å‘é‡åº“...")
index = faiss.read_index(os.path.join(INDEX_PATH, "index.faiss"))
with open(os.path.join(INDEX_PATH, "texts.pkl"), "rb") as f:
    texts = pickle.load(f)
print(f"âœ… å‘é‡åº“å°±ç»ªï¼Œå…± {index.ntotal} æ¡å¿ƒç†å’¨è¯¢å¯¹è¯")

print("\n[4/4] åŠ è½½ LMDeploy pipelineï¼ˆGPUï¼Œéœ€è¦1-2åˆ†é’Ÿï¼‰...")
engine_config = TurbomindEngineConfig(
    model_format='awq',
    quant_policy=4,
    tp=1,
    max_batch_size=1,
    cache_max_entry_count=0.8
)
pipe = lmdeploy_pipeline(LLM_PATH, backend_config=engine_config)
print("âœ… Qwen3-32B-AWQ æ¨¡å‹å°±ç»ª")
print("=" * 60)

# ========== è®¾ç½®å…¨å±€å˜é‡ä¾›è·¯ç”±æ¨¡å—ä½¿ç”¨ ==========
# ä¸ºæ‰€æœ‰è·¯ç”±æ¨¡å—è®¾ç½®å…¨å±€å˜é‡
import chat_routes, health_routes, crisis_routes, memory_routes, emotion_routes, personality_routes, recommendation_routes, report_routes

# èŠå¤©è·¯ç”±
chat_routes.llm_pipe = pipe
chat_routes.embed_model = embed_model
chat_routes.tokenizer = tokenizer
chat_routes.index = index
chat_routes.texts = texts
chat_routes.emotion_tracker = emotion_tracker
chat_routes.crisis_detector = crisis_detector

# å¥åº·æ£€æŸ¥è·¯ç”±
health_routes.crisis_detector = crisis_detector
health_routes.emotion_tracker = emotion_tracker
health_routes.index = index
health_routes.embed_model = embed_model
health_routes.llm_pipe = pipe

# å±æœºæ£€æµ‹è·¯ç”±
crisis_routes.crisis_detector = crisis_detector

# æƒ…ç»ªåˆ†æè·¯ç”±
emotion_routes.emotion_tracker = emotion_tracker

# ä¸ªæ€§åŒ–å»ºè®®è·¯ç”±
recommendation_routes.recommendation_engine = recommendation_engine
recommendation_routes.personality_profiler = personality_profiler
recommendation_routes.emotion_tracker = emotion_tracker
recommendation_routes.get_user_memory = get_user_memory

# äººæ ¼ç”»åƒè·¯ç”±
personality_routes.personality_profiler = personality_profiler

# ========== æ³¨å†Œæ‰€æœ‰è·¯ç”± ==========
app.include_router(chat_router)
app.include_router(health_router)
app.include_router(crisis_router)
app.include_router(memory_router)
app.include_router(emotion_router)
app.include_router(personality_router)
app.include_router(recommendation_router)
app.include_router(report_router)

# ========== å¯åŠ¨ä¿¡æ¯ ==========
@app.on_event("startup")
async def startup_event():
    print("\nğŸ¯ PsyCounselor API æœåŠ¡å¯åŠ¨å®Œæˆ!")
    print("ğŸ“š å¯ç”¨æ¥å£:")
    print("   POST /api/ask                 - å¿ƒç†å’¨è¯¢å¯¹è¯")
    print("   GET  /api/health              - ç³»ç»Ÿå¥åº·æ£€æŸ¥")
    print("   POST /api/emotion/analyze     - æƒ…ç»ªåˆ†æ")
    print("   POST /api/personality/analyze - äººæ ¼ç”»åƒåˆ†æ")
    print("   POST /api/recommendations/generate - ä¸ªæ€§åŒ–å»ºè®®ç”Ÿæˆ")
    print("   æ›´å¤šæ¥å£è¯·æŸ¥çœ‹APIæ–‡æ¡£...")

if __name__ == "__main__":
    import uvicorn
    print("\nğŸ¯ å¯åŠ¨ FastAPI æœåŠ¡...")
    uvicorn.run(app, host="0.0.0.0", port=8001)